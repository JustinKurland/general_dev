{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHeh2sv_hzt4"
      },
      "outputs": [],
      "source": [
        "@patch(\"rss_collector.utils.get_proxy_settings\")\n",
        "@patch(\"rss_collector.proxy.fetch_feed_content_with_proxy\")\n",
        "@patch(\"rss_collector.feed_parser.parse_feed\")\n",
        "def test_process_feeds(\n",
        "    mock_parse_feed, mock_fetch_feed, mock_get_proxy_settings, mock_feed_data, mock_proxy_settings, test_feed_urls\n",
        "):\n",
        "    print(\"=== Starting test_process_feeds ===\")\n",
        "\n",
        "    # Mock proxy settings\n",
        "    mock_get_proxy_settings.return_value = mock_proxy_settings\n",
        "    print(\"Mocked get_proxy_settings return value:\", mock_proxy_settings)\n",
        "\n",
        "    # Mock fetch_feed_content_with_proxy to return mock feed content\n",
        "    mock_fetch_feed.return_value = \"Mock RSS Feed Content\"\n",
        "    print(\"Mocked fetch_feed_content_with_proxy return value: 'Mock RSS Feed Content'\")\n",
        "\n",
        "    # Mock parse_feed to return the mocked feed data\n",
        "    mock_parse_feed.return_value = mock_feed_data\n",
        "    print(\"Mocked parse_feed return value:\", mock_feed_data)\n",
        "\n",
        "    # Call the process_feeds function\n",
        "    process_feeds(test_feed_urls)\n",
        "\n",
        "    print(\"=== Finished process_feeds call ===\")\n",
        "\n",
        "    # Assertions for get_proxy_settings\n",
        "    mock_get_proxy_settings.assert_called_once()\n",
        "    print(\"get_proxy_settings called once\")\n",
        "\n",
        "    # Assertions for fetch_feed_content_with_proxy\n",
        "    assert mock_fetch_feed.call_count == len(test_feed_urls)\n",
        "    print(\"fetch_feed_content_with_proxy called for each feed URL\")\n",
        "\n",
        "    # Assertions for parse_feed\n",
        "    assert mock_parse_feed.call_count == len(test_feed_urls)\n",
        "    print(\"parse_feed called for each feed URL\")\n",
        "\n",
        "    # Verify JSON file creation\n",
        "    output_dir = \"rss_metadata\"\n",
        "    saved_files = os.listdir(output_dir)\n",
        "    print(\"Saved files in output_dir:\", saved_files)\n",
        "    assert len(saved_files) == 1  # Only one consolidated JSON file should be created\n",
        "\n",
        "    # Validate JSON content\n",
        "    output_file = os.path.join(output_dir, saved_files[0])\n",
        "    with open(output_file, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    assert \"timestamp\" in metadata\n",
        "    assert \"articles\" in metadata\n",
        "    assert len(metadata[\"articles\"]) == len(mock_feed_data[\"entries\"])\n",
        "    print(\"Validated JSON content structure\")\n",
        "\n",
        "    # Cleanup created files\n",
        "    for file in saved_files:\n",
        "        os.remove(os.path.join(output_dir, file))\n",
        "    os.rmdir(output_dir)\n",
        "    print(\"Cleaned up output directory\")\n"
      ]
    }
  ]
}